{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c358a2-4c2b-4bf5-863c-ef67c9fd6d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "                event_time event_type  product_id          category_id  \\\n",
      "0  2019-10-01 00:00:00 UTC       view    44600062  2103807459595387724   \n",
      "1  2019-10-01 00:00:00 UTC       view     3900821  2053013552326770905   \n",
      "2  2019-10-01 00:00:01 UTC       view    17200506  2053013559792632471   \n",
      "3  2019-10-01 00:00:01 UTC       view     1307067  2053013558920217191   \n",
      "4  2019-10-01 00:00:04 UTC       view     1004237  2053013555631882655   \n",
      "\n",
      "                         category_code     brand    price    user_id  \\\n",
      "0                                  NaN  shiseido    35.79  541312140   \n",
      "1  appliances.environment.water_heater      aqua    33.20  554748717   \n",
      "2           furniture.living_room.sofa       NaN   543.10  519107250   \n",
      "3                   computers.notebook    lenovo   251.74  550050854   \n",
      "4               electronics.smartphone     apple  1081.98  535871217   \n",
      "\n",
      "                           user_session  \n",
      "0  72d76fde-8bb3-4e00-8c23-a032dfed738c  \n",
      "1  9333dfbd-b87a-4708-9857-6336556b0fcc  \n",
      "2  566511c2-e2e3-422b-b695-cf8e6e792ca8  \n",
      "3  7c90fc70-0e80-4590-96f3-13c02c18c713  \n",
      "4  c6bd7419-2748-4c56-95b4-8cec9ff8b80d  \n",
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42448764 entries, 0 to 42448763\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count     Dtype  \n",
      "---  ------         --------------     -----  \n",
      " 0   event_time     42448764 non-null  object \n",
      " 1   event_type     42448764 non-null  object \n",
      " 2   product_id     42448764 non-null  int64  \n",
      " 3   category_id    42448764 non-null  int64  \n",
      " 4   category_code  28933155 non-null  object \n",
      " 5   brand          36331684 non-null  object \n",
      " 6   price          42448764 non-null  float64\n",
      " 7   user_id        42448764 non-null  int64  \n",
      " 8   user_session   42448762 non-null  object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to our data file\n",
    "file_path = 'ecommerce-behavior-data-from-multi-category-store/2019-Oct.csv'\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows to see the structure\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Get a concise summary of the DataFrame\n",
    "print(\"\\nDataset information:\")\n",
    "df.info(show_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e49666-6561-46f7-a7e9-83098f391c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 42448762 entries, 0 to 42448763\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count     Dtype              \n",
      "---  ------         --------------     -----              \n",
      " 0   event_time     42448762 non-null  datetime64[ns, UTC]\n",
      " 1   event_type     42448762 non-null  category           \n",
      " 2   product_id     42448762 non-null  int64              \n",
      " 3   category_id    42448762 non-null  int64              \n",
      " 4   category_code  42448762 non-null  category           \n",
      " 5   brand          42448762 non-null  category           \n",
      " 6   price          42448762 non-null  float64            \n",
      " 7   user_id        42448762 non-null  int64              \n",
      " 8   user_session   42448762 non-null  object             \n",
      "dtypes: category(3), datetime64[ns, UTC](1), float64(1), int64(3), object(1)\n",
      "memory usage: 2.4+ GB\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Drop rows with missing user_session ---\n",
    "df.dropna(subset=['user_session'], inplace=True)\n",
    "\n",
    "# --- 2. Fill missing category_code and brand ---\n",
    "# This explicitly assigns the modified column back to the DataFrame.\n",
    "df['category_code'] = df['category_code'].fillna('unknown')\n",
    "df['brand'] = df['brand'].fillna('unknown')\n",
    "\n",
    "# --- 3. Optimize Data Types ---\n",
    "df['event_time'] = pd.to_datetime(df['event_time'])\n",
    "df['event_type'] = df['event_type'].astype('category')\n",
    "df['category_code'] = df['category_code'].astype('category')\n",
    "df['brand'] = df['brand'].astype('category')\n",
    "\n",
    "# --- 4. Verify the changes ---\n",
    "print(\"Cleaned dataset information:\")\n",
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525b6147-81c1-470e-a370-3ca1b18d9691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting events by session and time...\n",
      "Grouping events into sessions...\n",
      "\n",
      "Here are the first 5 sessions we created:\n",
      "user_session\n",
      "00000042-3e3f-42f9-810d-f3d264139c50                                 [54900011, 54900011]\n",
      "00000056-a206-40dd-b174-a072550fa38c    [1005115, 1005105, 1005105, 5100816, 1004858, ...\n",
      "00000083-8816-4d58-a9b8-f52f54186edc    [1004768, 1005098, 1005073, 1004871, 1004751, ...\n",
      "000001fd-1f89-45e8-a3ce-fe3218cabfad    [1004856, 1004856, 1004863, 1004834, 1004834, ...\n",
      "000003eb-b63e-45d9-9f26-f229057c654a                                            [2501061]\n",
      "Name: product_id, dtype: object\n",
      "\n",
      "Total unique sessions in October: 9,244,421\n"
     ]
    }
   ],
   "source": [
    "# First, sort the entire DataFrame. This is crucial for getting the correct event order.\n",
    "print(\"Sorting events by session and time...\")\n",
    "df.sort_values(by=['user_session', 'event_time'], inplace=True)\n",
    "\n",
    "# Group by 'user_session' and aggregate the 'product_id's into a list\n",
    "print(\"Grouping events into sessions...\")\n",
    "sessions = df.groupby('user_session')['product_id'].apply(list)\n",
    "\n",
    "print(\"\\nHere are the first 5 sessions we created:\")\n",
    "print(sessions.head())\n",
    "\n",
    "# Let's see how many unique sessions we have\n",
    "print(f\"\\nTotal unique sessions in October: {sessions.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61b600f-1a49-46e0-b776-d5113d11d04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning sessions by removing consecutive duplicates...\n",
      "Filtering out short sessions...\n",
      "\n",
      "Original number of sessions: 9,244,421\n",
      "Number of sessions after cleaning: 4,619,239\n",
      "\n",
      "Here are the first 5 cleaned sessions:\n",
      "user_session\n",
      "00000056-a206-40dd-b174-a072550fa38c    [1005115, 1005105, 5100816, 1004858, 1005104, ...\n",
      "00000083-8816-4d58-a9b8-f52f54186edc    [1004768, 1005098, 1005073, 1004871, 1004751, ...\n",
      "000001fd-1f89-45e8-a3ce-fe3218cabfad                          [1004856, 1004863, 1004834]\n",
      "0000047e-bdcc-4854-9e8d-9da7f84010ae                                   [2701673, 2701773]\n",
      "00000809-9101-4e4b-9795-e6cbafccfe19                 [2900090, 2900802, 2900803, 2900802]\n",
      "Name: product_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to remove consecutive duplicates\n",
    "def remove_consecutive_duplicates(item_list):\n",
    "    if not item_list:\n",
    "        return []\n",
    "    # Create a new list, adding items only if they are different from the last item added\n",
    "    new_list = [item_list[0]]\n",
    "    for item in item_list[1:]:\n",
    "        if item != new_list[-1]:\n",
    "            new_list.append(item)\n",
    "    return new_list\n",
    "\n",
    "print(\"Cleaning sessions by removing consecutive duplicates...\")\n",
    "cleaned_sessions = sessions.apply(remove_consecutive_duplicates)\n",
    "\n",
    "# Filter out sessions that are now too short (fewer than 2 items)\n",
    "print(\"Filtering out short sessions...\")\n",
    "final_sessions = cleaned_sessions[cleaned_sessions.apply(len) >= 2]\n",
    "\n",
    "\n",
    "print(f\"\\nOriginal number of sessions: {len(sessions):,}\")\n",
    "print(f\"Number of sessions after cleaning: {len(final_sessions):,}\")\n",
    "print(\"\\nHere are the first 5 cleaned sessions:\")\n",
    "print(final_sessions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92decc3f-3592-4ad5-84e7-682587936af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned sessions have been saved to 'october_sessions_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the processed sessions to a file for easy access later\n",
    "final_sessions.to_csv('october_sessions_cleaned.csv')\n",
    "\n",
    "print(\"\\nCleaned sessions have been saved to 'october_sessions_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25dfe93e-a025-4005-8277-f32a725d44a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned sessions...\n",
      "Building co-occurrence matrix...\n",
      "Co-occurrence matrix built successfully!\n",
      "Saving the model...\n",
      "Model has been saved successfully to 'co_occurrence_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "# --- Re-run the entire process with the fix ---\n",
    "\n",
    "# Load our cleaned sessions\n",
    "print(\"Loading cleaned sessions...\")\n",
    "df_sessions_df = pd.read_csv('october_sessions_cleaned.csv', index_col=0)\n",
    "df_sessions = df_sessions_df.iloc[:, 0]\n",
    "df_sessions = df_sessions.apply(ast.literal_eval)\n",
    "\n",
    "# Define a named function to create the nested defaultdict\n",
    "def nested_dd():\n",
    "    return defaultdict(int)\n",
    "\n",
    "# Use the named function instead of a lambda\n",
    "co_occurrence_matrix = defaultdict(nested_dd)\n",
    "\n",
    "print(\"Building co-occurrence matrix...\")\n",
    "for session in df_sessions:\n",
    "    for i in range(len(session) - 1):\n",
    "        current_item = session[i]\n",
    "        next_item = session[i+1]\n",
    "        co_occurrence_matrix[current_item][next_item] += 1\n",
    "\n",
    "print(\"Co-occurrence matrix built successfully!\")\n",
    "\n",
    "# --- Now, save the model ---\n",
    "print(\"Saving the model...\")\n",
    "with open('co_occurrence_model.pkl', 'wb') as f:\n",
    "    pickle.dump(co_occurrence_matrix, f)\n",
    "\n",
    "print(\"Model has been saved successfully to 'co_occurrence_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "978f123f-97ab-4815-ac37-eccbc1f0f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (co-occurrence matrix) has been saved to 'co_occurrence_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the co-occurrence matrix to a file\n",
    "with open('co_occurrence_model.pkl', 'wb') as f:\n",
    "    pickle.dump(co_occurrence_matrix, f)\n",
    "\n",
    "print(\"Model (co-occurrence matrix) has been saved to 'co_occurrence_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ba71c4-043e-4e73-b39d-b59e922aa135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cleaned sessions...\n",
      "Converting product IDs to strings...\n",
      "Training Word2Vec model... (This will take a few minutes)\n",
      "Model training complete.\n",
      "Word2Vec model saved to 'product_w2v.model'\n",
      "\n",
      "Top 5 most similar items to 1005115:\n",
      "[('1005135', 0.8431757092475891), ('1005104', 0.8268886208534241), ('1004249', 0.81839519739151), ('1003317', 0.8180369138717651), ('1004258', 0.8162089586257935)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your cleaned sessions again\n",
    "print(\"Loading cleaned sessions...\")\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df_sessions_df = pd.read_csv('october_sessions_cleaned.csv', index_col=0)\n",
    "\n",
    "# Select the first (and only) column to create the Series\n",
    "df_sessions = df_sessions_df.iloc[:, 0]\n",
    "\n",
    "# Convert it to a list\n",
    "sessions_as_lists = df_sessions.apply(ast.literal_eval)\n",
    "\n",
    "# The model needs the product_ids to be strings\n",
    "print(\"Converting product IDs to strings...\")\n",
    "sessions_as_strings = [[str(item) for item in session] for session in sessions_as_lists]\n",
    "\n",
    "# --- Train the Word2Vec Model ---\n",
    "print(\"Training Word2Vec model... (This will take a few minutes)\")\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sessions_as_strings,\n",
    "    vector_size=100,  # The dimensionality of the product vectors\n",
    "    window=5,         # Max distance between current and predicted product within a session\n",
    "    min_count=5,      # Ignores all products with total frequency lower than this\n",
    "    workers=4         # Use 4 worker threads to train the model\n",
    ")\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# --- Save the new model ---\n",
    "w2v_model.save(\"product_w2v.model\")\n",
    "print(\"Word2Vec model saved to 'product_w2v.model'\")\n",
    "\n",
    "# --- Let's Test It ---\n",
    "# Get an example item from our first session\n",
    "example_item_id = sessions_as_strings[0][0]\n",
    "\n",
    "# Find the top 5 most similar items\n",
    "print(f\"\\nTop 5 most similar items to {example_item_id}:\")\n",
    "similar_items = w2v_model.wv.most_similar(example_item_id, topn=5)\n",
    "print(similar_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c72ad0-e541-4eae-98fa-6326ac05872a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
